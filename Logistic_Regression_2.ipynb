{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9B_EK4Me9ix"
      },
      "outputs": [],
      "source": [
        "# Q1: Purpose of Grid Search CV in machine learning\n",
        "\n",
        "# Grid Search CV (Cross-Validation):\n",
        "# - It is used to find the best hyperparameters for a machine learning model.\n",
        "# - Works by exhaustively searching through a specified set of hyperparameters.\n",
        "# - Evaluates each combination using cross-validation to identify the best-performing configuration.\n",
        "\n",
        "# Example in Python:\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define model and parameter grid\n",
        "model = RandomForestClassifier()\n",
        "param_grid = {'n_estimators': [50, 100, 150], 'max_depth': [None, 10, 20]}\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Q2: Difference between Grid Search CV and Randomized Search CV\n",
        "\n",
        "# Grid Search CV:\n",
        "# - Tests all possible combinations of hyperparameters.\n",
        "# - Computationally expensive for large parameter spaces.\n",
        "\n",
        "# Randomized Search CV:\n",
        "# - Randomly samples a fixed number of combinations from the hyperparameter space.\n",
        "# - More efficient for large or complex parameter spaces.\n",
        "\n",
        "# Example of Randomized Search:\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=5)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters from Randomized Search:\", random_search.best_params_)\n",
        "\n",
        "# Q3: What is data leakage, and why is it a problem?\n",
        "\n",
        "# Data leakage occurs when information from outside the training dataset is used to create the model.\n",
        "# It can lead to overly optimistic performance during training but poor generalization.\n",
        "\n",
        "# Example:\n",
        "# Including future data (e.g., target values) as features in the training data.\n",
        "\n",
        "# Q4: How to prevent data leakage?\n",
        "\n",
        "# 1. Properly split data into training, validation, and testing sets.\n",
        "# 2. Perform data preprocessing (e.g., scaling, encoding) separately on training and testing data.\n",
        "# 3. Avoid including features that won't be available in real-world scenarios.\n",
        "\n",
        "# Example: Using scikit-learn's Pipeline to prevent leakage:\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Q5: What is a confusion matrix?\n",
        "\n",
        "# A confusion matrix is a table that summarizes the performance of a classification model.\n",
        "# It shows the counts of True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN).\n",
        "\n",
        "# Example:\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Q6: Precision vs. Recall\n",
        "\n",
        "# Precision: Proportion of true positive predictions out of all positive predictions.\n",
        "# Formula: Precision = TP / (TP + FP)\n",
        "\n",
        "# Recall: Proportion of true positives out of all actual positive cases.\n",
        "# Formula: Recall = TP / (TP + FN)\n",
        "\n",
        "# Q7: Interpreting confusion matrix to identify errors\n",
        "\n",
        "# - FP: Type I Error (false alarms).\n",
        "# - FN: Type II Error (missed detections).\n",
        "# Example: Look at the off-diagonal elements of the confusion matrix.\n",
        "\n",
        "# Q8: Metrics derived from a confusion matrix\n",
        "\n",
        "# 1. Accuracy: (TP + TN) / Total\n",
        "# 2. Precision: TP / (TP + FP)\n",
        "# 3. Recall: TP / (TP + FN)\n",
        "# 4. F1 Score: 2 * (Precision * Recall) / (Precision + Recall)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Q9: Relationship between accuracy and confusion matrix\n",
        "\n",
        "# Accuracy depends on all elements of the confusion matrix.\n",
        "# Example: High accuracy in imbalanced datasets might be misleading due to TN dominance.\n",
        "\n",
        "# Q10: Identifying biases or limitations from confusion matrix\n",
        "\n",
        "# Analyze:\n",
        "# - High FP: Indicates over-prediction of positive class.\n",
        "# - High FN: Indicates under-prediction of positive class.\n",
        "# Bias Example: A model biased towards the majority class will show very few FN for the majority class.\n",
        "\n",
        "# Addressing bias: Use balanced datasets, resampling techniques, or adjust class weights.\n",
        "\n",
        "# Example of class imbalance handling with balanced class weights:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X_train, y_train)\n"
      ]
    }
  ]
}